{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30763,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer,  GenerationConfig\nimport torch\n!pip install datasets\nimport time\nimport re\nfrom difflib import SequenceMatcher","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-22T07:49:54.947907Z","iopub.execute_input":"2024-09-22T07:49:54.948357Z","iopub.status.idle":"2024-09-22T07:50:15.644230Z","shell.execute_reply.started":"2024-09-22T07:49:54.948304Z","shell.execute_reply":"2024-09-22T07:50:15.642863Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:50:15.646557Z","iopub.execute_input":"2024-09-22T07:50:15.647501Z","iopub.status.idle":"2024-09-22T07:50:17.013250Z","shell.execute_reply.started":"2024-09-22T07:50:15.647448Z","shell.execute_reply":"2024-09-22T07:50:17.012259Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"model_id1 = \"google/gemma-2b-it\"\nmodel_id2 = \"microsoft/Phi-3.5-mini-instruct\"\nmodel_id3 = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:50:17.014683Z","iopub.execute_input":"2024-09-22T07:50:17.015231Z","iopub.status.idle":"2024-09-22T07:50:17.019884Z","shell.execute_reply.started":"2024-09-22T07:50:17.015195Z","shell.execute_reply":"2024-09-22T07:50:17.018845Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:50:17.022356Z","iopub.execute_input":"2024-09-22T07:50:17.022772Z","iopub.status.idle":"2024-09-22T07:50:31.256877Z","shell.execute_reply.started":"2024-09-22T07:50:17.022720Z","shell.execute_reply":"2024-09-22T07:50:31.255081Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.7.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:50:31.258402Z","iopub.execute_input":"2024-09-22T07:50:31.258777Z","iopub.status.idle":"2024-09-22T07:50:31.368842Z","shell.execute_reply.started":"2024-09-22T07:50:31.258740Z","shell.execute_reply":"2024-09-22T07:50:31.367955Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer1 = AutoTokenizer.from_pretrained(model_id1)\nmodel1 = AutoModelForCausalLM.from_pretrained(model_id1).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:50:31.370350Z","iopub.execute_input":"2024-09-22T07:50:31.371150Z","iopub.status.idle":"2024-09-22T07:51:21.171344Z","shell.execute_reply.started":"2024-09-22T07:50:31.371087Z","shell.execute_reply":"2024-09-22T07:51:21.170210Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92a7e60eb1fd44dda0ff6c0e7647a913"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24411e7bbc7d49b5bd9c1f1b85d54cce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd31c6b65b104e1db83e351cc2e54de7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff8380ccb4a1430aa784c7b1ffbcb26f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d1665cf9873455580c212609e276aea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fff61e4927834d26b2d219e48d7b3d47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed4ae52078a475983d462b02e60aca5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07f99934c91a48faafa474d758bee7a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b90f95c7602a4540aa9a16c1fff8a0f9"}},"metadata":{}},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40c29eae0bb346a08bc7b66cfcc03d56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b44531179cac49a0914f23f46798af41"}},"metadata":{}}]},{"cell_type":"code","source":"# tokenizer2 = AutoTokenizer.from_pretrained(model_id2)\n# model2 = AutoModelForCausalLM.from_pretrained(model_id2).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:21.172737Z","iopub.execute_input":"2024-09-22T07:51:21.173428Z","iopub.status.idle":"2024-09-22T07:51:21.178114Z","shell.execute_reply.started":"2024-09-22T07:51:21.173365Z","shell.execute_reply":"2024-09-22T07:51:21.177073Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# tokenizer3 = AutoTokenizer.from_pretrained(model_id3)\n# model3 = AutoModelForCausalLM.from_pretrained(model_id3).to(device) ","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:21.179392Z","iopub.execute_input":"2024-09-22T07:51:21.179704Z","iopub.status.idle":"2024-09-22T07:51:21.189386Z","shell.execute_reply.started":"2024-09-22T07:51:21.179672Z","shell.execute_reply":"2024-09-22T07:51:21.188545Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def generate_response(prompt,model,tokenizer,new_tokens):\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n\n    with torch.no_grad():\n        outputs = model.generate(inputs.input_ids, max_new_tokens=new_tokens, num_return_sequences=1)\n\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return response","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:21.190664Z","iopub.execute_input":"2024-09-22T07:51:21.191326Z","iopub.status.idle":"2024-09-22T07:51:21.200382Z","shell.execute_reply.started":"2024-09-22T07:51:21.191279Z","shell.execute_reply":"2024-09-22T07:51:21.199492Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"cais/mmlu\",\"college_mathematics\")\ndataset = dataset['test']\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:21.204222Z","iopub.execute_input":"2024-09-22T07:51:21.204576Z","iopub.status.idle":"2024-09-22T07:51:24.267553Z","shell.execute_reply.started":"2024-09-22T07:51:21.204529Z","shell.execute_reply":"2024-09-22T07:51:24.266585Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/53.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d38e5b6e6d5d435ebf546103ac1b2ff7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/138k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ed2f656b28b4e67a3a5ee1960086152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/16.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dd588face0f4ef1b58f628bc9f8e020"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1d895f405504770b70df1d6efd4a9d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cbf28a398c54523b0b62d16941ccef1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fd664e470a346f084ebac9197aa4129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7080c5a5fed4f1092945dfce201b3fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f40010294bf47f898cf05d2d756f126"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question', 'subject', 'choices', 'answer'],\n    num_rows: 100\n})"},"metadata":{}}]},{"cell_type":"code","source":"prompts_zero_shot=[]\nfor example in dataset:\n    question = example['question']\n    options = example['choices']  \n    prompt = f\"Choose the answer to the given question from below options.\\nQuestion:{question}\\nOption 1:{options[0]}\\nOption 2:{options[1]}\\nOption 3: {options[2]}\\nOption 4: {options[3]}.\"\n    prompts_zero_shot.append(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:24.268793Z","iopub.execute_input":"2024-09-22T07:51:24.269248Z","iopub.status.idle":"2024-09-22T07:51:24.286548Z","shell.execute_reply.started":"2024-09-22T07:51:24.269216Z","shell.execute_reply":"2024-09-22T07:51:24.285530Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"prompts_cot=[]\nfor example in dataset:\n    question = example['question']\n    options = example['choices']  \n    prompt = f\"Choose the answer to the given question from below options.\\nQuestion:{question}\\nOption 1:{options[0]}\\nOption 2:{options[1]}\\nOption 3: {options[2]}\\nOption 4: {options[3]}\\nThink step by step.\"\n    prompts_cot.append(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:24.287930Z","iopub.execute_input":"2024-09-22T07:51:24.288323Z","iopub.status.idle":"2024-09-22T07:51:24.335014Z","shell.execute_reply.started":"2024-09-22T07:51:24.288287Z","shell.execute_reply":"2024-09-22T07:51:24.334140Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def extract_answer(response):\n    \n    match = re.search(r'(Therefore, the correct answer is|Therefore, the answer is|The correct answer is|the correct answer is|The answer is:|The answer is|Answer:|the answer is|the answer is:)\\s*(.*)', response)\n#     match = re.search(r'(Therefore,\\s*the\\s*correct\\s*answer\\s*is|The\\s*correct\\s*answer\\s*is|The\\s*answer\\s*is:|The\\s*answer\\s*is|Answer:|answer:)\\s*([^\\n]*)', response)\n\n    if match:\n        return match.group(2).strip()\n    return None\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:24.336478Z","iopub.execute_input":"2024-09-22T07:51:24.336877Z","iopub.status.idle":"2024-09-22T07:51:24.349633Z","shell.execute_reply.started":"2024-09-22T07:51:24.336842Z","shell.execute_reply":"2024-09-22T07:51:24.348784Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"options_val = [\"Option 1\",\"Option 2\",\"Option 3\",\"Option 4\",\"Option 1.\",\"Option 2.\",\"Option 3.\",\"Option 4.\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:24.350653Z","iopub.execute_input":"2024-09-22T07:51:24.351001Z","iopub.status.idle":"2024-09-22T07:51:24.359857Z","shell.execute_reply.started":"2024-09-22T07:51:24.350968Z","shell.execute_reply":"2024-09-22T07:51:24.358996Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def evaluate_zeroshot(model,tokenizer,prompts,model_name,dataset):\n    responses = []\n    start = time.time()\n    for i in prompts:\n        responses.append(generate_response(i,model,tokenizer,50))\n\n    end = time.time()\n    inference_time = (end - start)/100\n    print(f\"Inference time for zero shot for {model_name}: {inference_time:.6f} seconds\")\n    \n    \n    correct_count = 0\n    for i, example in enumerate(dataset):\n        extracted_answer = extract_answer(responses[i])\n        \n        if extracted_answer==None:\n            extracted_answer = \"??\"\n        \n        if extracted_answer in options_val:\n            extracted_answer = example['choices'][int(extracted_answer[7])-1]\n\n        actual_answer = example['choices'][example['answer']]\n\n        if extracted_answer in actual_answer or actual_answer in extracted_answer:\n            correct_count += 1\n\n    accuracy = correct_count / len(dataset)\n    print(f\"Accuracy of {model_name} for zero shot: {accuracy:.2f}\")    ","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:24.361082Z","iopub.execute_input":"2024-09-22T07:51:24.361430Z","iopub.status.idle":"2024-09-22T07:51:24.371498Z","shell.execute_reply.started":"2024-09-22T07:51:24.361398Z","shell.execute_reply":"2024-09-22T07:51:24.370627Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def evaluate_cot(model,tokenizer,prompts,model_name,dataset):\n    responses = []\n    start = time.time()\n    for i in prompts:\n        responses.append(generate_response(i,model,tokenizer,150))\n\n    end = time.time()\n    inference_time = (end - start)/100\n    print(f\"Inference time for chain of thought for {model_name}: {inference_time:.6f} seconds\")\n    \n    correct_count = 0\n    for i, example in enumerate(dataset):\n        extracted_answer = extract_answer(responses[i])\n        if extracted_answer==None:\n            extracted_answer = \"??\"\n        \n        if extracted_answer in options_val:\n            extracted_answer = example['choices'][int(extracted_answer[7])-1]\n\n        actual_answer = example['choices'][example['answer']]\n\n        if extracted_answer in actual_answer or actual_answer in extracted_answer:\n            correct_count += 1\n\n    accuracy = correct_count / len(dataset)\n    print(f\"Accuracy of {model_name}  for cot: {accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:24.372638Z","iopub.execute_input":"2024-09-22T07:51:24.373000Z","iopub.status.idle":"2024-09-22T07:51:24.382044Z","shell.execute_reply.started":"2024-09-22T07:51:24.372967Z","shell.execute_reply":"2024-09-22T07:51:24.381183Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"evaluate_zeroshot(model1,tokenizer1,prompts_zero_shot,\"Gemma\",dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:51:24.383161Z","iopub.execute_input":"2024-09-22T07:51:24.384025Z","iopub.status.idle":"2024-09-22T07:54:57.187199Z","shell.execute_reply.started":"2024-09-22T07:51:24.383978Z","shell.execute_reply":"2024-09-22T07:54:57.186149Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Inference time for zero shot for Gemma: 2.127796 seconds\nAccuracy of Gemma for zero shot: 0.39\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate_zeroshot(model2,tokenizer2,prompts_zero_shot,\"Phi-3.5\",dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:54:57.188661Z","iopub.execute_input":"2024-09-22T07:54:57.189289Z","iopub.status.idle":"2024-09-22T07:54:57.193466Z","shell.execute_reply.started":"2024-09-22T07:54:57.189248Z","shell.execute_reply":"2024-09-22T07:54:57.192495Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# evaluate_zeroshot(model3,tokenizer3,prompts_zero_shot,\"Llama-3.1\",dataset) ","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:54:57.194843Z","iopub.execute_input":"2024-09-22T07:54:57.195228Z","iopub.status.idle":"2024-09-22T07:54:57.208325Z","shell.execute_reply.started":"2024-09-22T07:54:57.195183Z","shell.execute_reply":"2024-09-22T07:54:57.207245Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"evaluate_cot(model1,tokenizer1,prompts_cot,\"Gemma\",dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:54:57.209794Z","iopub.execute_input":"2024-09-22T07:54:57.210671Z","iopub.status.idle":"2024-09-22T08:03:39.440463Z","shell.execute_reply.started":"2024-09-22T07:54:57.210622Z","shell.execute_reply":"2024-09-22T08:03:39.439420Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Inference time for chain of thought for Gemma: 5.222095 seconds\nAccuracy of Gemma  for cot: 0.21\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate_cot(model2,tokenizer2,prompts_cot,\"Phi-3.5\",dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:03:39.441647Z","iopub.execute_input":"2024-09-22T08:03:39.441973Z","iopub.status.idle":"2024-09-22T08:03:39.446751Z","shell.execute_reply.started":"2024-09-22T08:03:39.441937Z","shell.execute_reply":"2024-09-22T08:03:39.445712Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# evaluate_cot(model3,tokenizer3,prompts_cot,\"Llama-3.1\",dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:03:39.447897Z","iopub.execute_input":"2024-09-22T08:03:39.448199Z","iopub.status.idle":"2024-09-22T08:03:39.463405Z","shell.execute_reply.started":"2024-09-22T08:03:39.448166Z","shell.execute_reply":"2024-09-22T08:03:39.462308Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# responses = []\n# start = time.time()\n# j=0\n# for i in prompts_cot:\n#     responses.append(generate_response(i,model1,tokenizer1,150))\n#     print(responses[j])\n#     j=j+1\n\n# end = time.time()\n# inference_time = (end - start)/100\n# print(f\"Inference time for cot for gemma: {inference_time:.6f} seconds\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:03:39.464723Z","iopub.execute_input":"2024-09-22T08:03:39.465009Z","iopub.status.idle":"2024-09-22T08:03:39.475502Z","shell.execute_reply.started":"2024-09-22T08:03:39.464979Z","shell.execute_reply":"2024-09-22T08:03:39.474632Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# correct_count = 0\n# for i, example in enumerate(dataset):\n#     extracted_answer = extract_answer(responses[i])\n#     if extracted_answer==None:\n#         extracted_answer = \"??\"\n\n#     if extracted_answer in options_val:\n#             extracted_answer = example['choices'][int(extracted_answer[7])-1]\n\n#     actual_answer = example['choices'][example['answer']]\n#     print(extracted_answer)\n#     print(actual_answer)\n    \n#     if extracted_answer in actual_answer or actual_answer in extracted_answer:\n#         correct_count += 1\n#         print(\"HA\")\n\n# accuracy = correct_count / len(dataset)\n# print(f\"Accuracy of {model_name} for zero shot: {accuracy:.2f}\")    ","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:03:39.476653Z","iopub.execute_input":"2024-09-22T08:03:39.476964Z","iopub.status.idle":"2024-09-22T08:03:39.487544Z","shell.execute_reply.started":"2024-09-22T08:03:39.476932Z","shell.execute_reply":"2024-09-22T08:03:39.486555Z"},"trusted":true},"execution_count":24,"outputs":[]}]}